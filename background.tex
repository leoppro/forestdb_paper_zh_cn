\section{背景}
\subsection{B$^+$树和前缀B$^+$树}

B$^+$树是块设备上最广泛的管理海量记录的索引结构之一。B$^+$树中有两种不同类型的节点：叶节点和索引（非叶）节点。不同于B树或其他二叉搜索树，键值记录只储存于叶节点，索引节点则包含子节点指针。在B$^+$树中，每个节点不只包含两个键值对（或键指针）；每结点中键值对的数量称作扇出。一般来说，为了使B$^+$树节点与一个或多个块对齐，B$^+$树的扇出会被设置为一个比较大的值。B$^+$树以这种方式降低每访问键值对产生的块I/O访问数。

然而，正如我们之前提到的，键长度对扇出影响极大。为了缓和这方面开销，前缀B$^+$树被提出了。前缀B$^+$树的主要思想是只存储可辨识的部分子串而不是整个字符串，通过这种方式节省存储空间，提高扇出。索引节点只储存最小的可区分其子节点的前缀，而叶节点则跳过同节点中相同的前缀。

\begin{figure}[htbp]
    \centering
    \begin{overpic}[scale=0.5]{bptree_and_prefix_bptree.png}
        \put(53,-3){\scriptsize 公共前缀：b}
        \put(86.5,-3){\scriptsize 公共前缀：d}
        \put(17,-7){\scriptsize (a)传统B$^+$树}
        \put(69,-7){\scriptsize (b)前缀B$^+$树}
    \end{overpic}
    \\[3em]
	\caption{B$^+$树及前缀B$^+$树示例\label{fig:bptree_and_prefix_bptree}}
\end{figure}

图\ref{fig:bptree_and_prefix_bptree}展示了一个B$^+$树和相应的前缀B$^+$树的例子。在前缀B$^+$树中，根（即索引节点）节点只存储字符串$c$而非整个键$car$，因为它是字典序大于$band$、$bingo$和$black$且小于等于$car$、$chalk$和$diary$的最小子串。但我们不能使用$d$代替$dim$因为$d$不能区分$diary$和$dime$。在本例中，前缀B$^+$树使用$dim$，因为它是字典序介于$diary$和$dime$的最小子串。

在叶节点中，最左边节点中的$band$、$bingo$和$black$有公共前缀$b$，最右边节点中的$dime$和$diary$和$dog$有公共前缀$d$。前缀B$^+$树在每个节点中的元数据部分记录这些公共前缀，只存储这些字符串的非公有部分。当大量的键有公共前缀时，这种前缀压缩方案有效的降低了空间开销。

\subsection{结构化日志合并树（LSM树）}

尽管B$^+$树可以使索引大量记录时产生的块访问量最小化，但由于随机块访问，依然可能会遇到性能不佳的问题。随时间推移，B$^+$树的节点将随机散落在硬盘上。这将在树遍历时产生块随机访问，从而引起性能大幅度降低。得益于B$^+$树最小化块访问的能力，几乎没有其他树型结构的随机读取性能比B$^+$树好，但我们仍然可以通过整理磁盘写入操作的思路提高其写入性能。

\begin{figure}[htbp]
    \centering
    \begin{overpic}[scale=1]{lsmtree.png}
        \put(9,18){\scriptsize C$_0$树}
        \put(39,5){\scriptsize C$_1$树}
        \put(74,5){\scriptsize C$_2$树}
        \put(7,5){\scriptsize 顺序日志}
        \put(25,22){\scriptsize 刷新}
        \put(53,22){\scriptsize 刷新}
        \put(9.5,27){\scriptsize 内存}
        \put(38,-2.5){\scriptsize 容量呈指数增长}
    \end{overpic}
    \\[1.5em]
	\caption{B$^+$树及前缀B$^+$树示例\label{fig:lsmtree}}
\end{figure}

LSM树是一种超越B$^+$树的随机写入性能的索引结构。如图\ref{fig:lsmtree}所示，一些B$^+$树或类B$^+$树结构组织一个单独的LSM树。在LSM树上层有一个存储于内存的树结构，被称为C$_0$树。所有更新记录追加至一个顺序日志中，C$_0$树索引着日志中的每一个项以便高效访问。一旦C$_0$树的尺寸超过了某个阈值，一段连续的日志记录将被合并进C$_1$树。当C$_1$树的尺寸超过某个阈值，C$_1$树中一段连续的记录会以同样的方式合并进C$_2$树。合并操作总是在C$_i$树和C$_{i+1}$树之间发生，通常树的容量随$i$指数增长。

因为追加日志和合并操作都是对磁盘的顺序写入，因此LSM树的写入性能要比传统B$^+$树好得多。然而要访问一个键值对，我们只能从C$_0$开始对所有的树进行级联查找，直到发现目标记录，因此LSM的读取开销较B$^+$树大。为了避免不必要的遍历操作，LSM树一般使用布隆过滤器减弱读放大效应。

第1章中提出的问题在LSM树中同样存在。如果键长度变长，较小的扇出会降低每棵树的容量，树间的合并操作将更加频繁。因为合并会触发大量I/O操作，导致性能的急剧下降。

\subsection{Couchstore}

\begin{figure}[htbp]
    \centering
    ~\\
    \begin{overpic}[scale=1]{couchstore.png}
        \put(55,2){\tiny 字节偏移量}
        \put(75,49){\scriptsize 最新数据}
        \put(75,42){\scriptsize 陈旧数据}
        \put(75,34){\scriptsize B$^+$树节点}
        \put(75,28){\scriptsize 文档}
        \put(66,11){\scriptsize 只追加}
        \put(4,19){\scriptsize DB文件的非结构化视图}
        \put(4,55){\scriptsize B$^+$树节点和文档的逻辑视图}
        \put(62,61){\scriptsize 单一Couchstore实例}
        \put(41,95){\scriptsize 键空间}
    \end{overpic}
	\caption{Couchstore概览\label{fig:couchstore}}
\end{figure}

Couchstore 是Couchbase中的单节点存储引擎，其整体架构继承自Apache CouchDB的存储模块。键空间被等分为若干用户定义的键范围数，我们称其为vBucket（或分区），每个vBucket拥有它自己的DB文件。每个DB文件所存储的键值对属于其对应的vBucket，每个键是一个任意长的字符串，每个值是JSON文档。为了确定文件中某个文档的位置，每个vBucket中有一个B$^+$树用于存储键和其对应文档的字节偏移量所构成的元组。因此，每一个DB文件包含文档和B$^+$树节点两部分，他们互相交错存储于文件中。

如图\ref{fig:couchstore}所示，在Couchstore中所有的更新操作都追加在DB文件的后面。$A$、$B$和$C$代表B$^+$树节点，在胶囊图形中的$D1$、$D2$和$D3$代表文档。如果$D1$文档更新了，新文档$D1'$将被写入文件末尾，而不会擦除或修改原文档$D1$。因为文档位置更新了，$B$节点必须更新为$B'$节点，同样追加至文件末尾。更新操作一直传递到根节点$A$，最终新根节点$A'$被写入到$B'$节点后。

相比于就地更新策略，只追加的B$^+$树可以实现非常高的写入吞吐量，因为所有的磁盘写入操作都是顺序的。此外，我们不需要牺牲读取性能，因为读取过程与传统B$^+$树是相同的。但是DB文件的占用空间随更新操作而增长，因此我们必须定期回收陈旧数据所占用的空间。当陈旧数据与总数据尺寸比超过一定预设阈值时，Couchstore触发器将执行这个压缩过程。当前目标DB文件中所有的文档将被移动到新DB文件，在压缩操作完成后，旧DB文件将被删除。在压缩过程中，所有对目标文件的写入操作将被阻塞，而读取操作是被允许的。每次仅对一个DB文件进行压缩。

与传统B$^+$树处理字符串的方式相同，为了维持容量不变，如果键长度增加，树的高度将增加。因为追加数据量与树高度成正比，因此这种只追加设计的性能衰减可能会更糟糕。由此导致压缩操作被更频繁的触发，整体性能陷入恶性循环。我们需要为变长字符串键设计一个更紧凑更有效的索引结构。